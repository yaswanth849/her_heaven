/*
Auto-generated by: https://github.com/pmndrs/gltfjsx
Command: npx gltfjsx@6.2.3 public/models/64f1a714fe61576b46f27ca2.glb -o src/components/Avatar.jsx -k -r public
*/

import { useAnimations, useGLTF } from "@react-three/drei";
import { useFrame } from "@react-three/fiber";
import { button, useControls } from "leva";
import React, { useEffect, useMemo, useRef, useState } from "react";

import * as THREE from "three";
import { useChat } from "../hooks/useChat";

const facialExpressions = {
  default: {},
  smile: {
    browInnerUp: 0.17,
    eyeSquintLeft: 0.4,
    eyeSquintRight: 0.44,
    noseSneerLeft: 0.1700000727403593,
    noseSneerRight: 0.14000002836874015,
    mouthPressLeft: 0.61,
    mouthPressRight: 0.41000000000000003,
  },
  funnyFace: {
    jawLeft: 0.63,
    mouthPucker: 0.53,
    noseSneerLeft: 1,
    noseSneerRight: 0.39,
    mouthLeft: 1,
    eyeLookUpLeft: 1,
    eyeLookUpRight: 1,
    cheekPuff: 0.9999924982764238,
    mouthDimpleLeft: 0.414743888682652,
    mouthRollLower: 0.32,
    mouthSmileLeft: 0.35499733688813034,
    mouthSmileRight: 0.35499733688813034,
  },
  sad: {
    mouthFrownLeft: 1,
    mouthFrownRight: 1,
    mouthShrugLower: 0.78341,
    browInnerUp: 0.452,
    eyeSquintLeft: 0.72,
    eyeSquintRight: 0.75,
    eyeLookDownLeft: 0.5,
    eyeLookDownRight: 0.5,
    jawForward: 1,
  },
  surprised: {
    eyeWideLeft: 0.5,
    eyeWideRight: 0.5,
    jawOpen: 0.351,
    mouthFunnel: 1,
    browInnerUp: 1,
  },
  angry: {
    browDownLeft: 1,
    browDownRight: 1,
    eyeSquintLeft: 1,
    eyeSquintRight: 1,
    jawForward: 1,
    jawLeft: 1,
    mouthShrugLower: 1,
    noseSneerLeft: 1,
    noseSneerRight: 0.42,
    eyeLookDownLeft: 0.16,
    eyeLookDownRight: 0.16,
    cheekSquintLeft: 1,
    cheekSquintRight: 1,
    mouthClose: 0.23,
    mouthFunnel: 0.63,
    mouthDimpleRight: 1,
  },
  crazy: {
    browInnerUp: 0.9,
    jawForward: 1,
    noseSneerLeft: 0.5700000000000001,
    noseSneerRight: 0.51,
    eyeLookDownLeft: 0.39435766259644545,
    eyeLookUpRight: 0.4039761421719682,
    eyeLookInLeft: 0.9618479575523053,
    eyeLookInRight: 0.9618479575523053,
    jawOpen: 0.9618479575523053,
    mouthDimpleLeft: 0.9618479575523053,
    mouthDimpleRight: 0.9618479575523053,
    mouthStretchLeft: 0.27893590769016857,
    mouthStretchRight: 0.2885543872656917,
    mouthSmileLeft: 0.5578718153803371,
    mouthSmileRight: 0.38473918302092225,
    tongueOut: 0.9618479575523053,
  },
};

const corresponding = {
  A: "viseme_PP",
  B: "viseme_kk",
  C: "viseme_I",
  D: "viseme_AA",
  E: "viseme_O",
  F: "viseme_U",
  G: "viseme_FF",
  H: "viseme_TH",
  X: "viseme_PP",
};

let setupMode = false;

export function Avatar(props) {
  const { nodes, materials, scene } = useGLTF(
    "/models/64f1a714fe61576b46f27ca2.glb"
  );

  const { message, onMessagePlayed, chat } = useChat();

  const [lipsync, setLipsync] = useState();
  // Audio element for current message playback (declared early so effects can depend on it safely)
  const [audio, setAudio] = useState();


  // Use existing GLTF animations (skeleton-matched) to avoid retargeting issues
  const { animations } = useGLTF("/models/animations.glb");

  // Filter out tracks that target nodes not present in the model to avoid THREE.PropertyBinding warnings
  const filteredAnimations = useMemo(() => {
    return animations.map((clip) => {
      const c = clip.clone();
      c.tracks = c.tracks.filter((track) => {
        const name = track.name || "";
        if (name.startsWith("Armature")) return false; // drop armature root animation
        if (name.endsWith(".position") || name.endsWith(".scale")) return false; // avoid moving/scaling avatar off-screen
        const nodeName = name.split(".")[0];
        return Boolean(nodes[nodeName] || scene.getObjectByName(nodeName));
      });
      return c;
    });
  }, [animations, nodes, scene]);

  const group = useRef();
  const { actions, mixer } = useAnimations(filteredAnimations, group);

  const initialAnim = useMemo(() => {
    const idle = filteredAnimations.find((a) => a.name === "Idle");
    return idle ? "Idle" : filteredAnimations[0]?.name || "";
  }, [filteredAnimations]);
  const [animation, setAnimation] = useState(initialAnim);
  useEffect(() => {
    if (initialAnim) setAnimation(initialAnim);
  }, [initialAnim]);

  // helper to convert base64 into a Blob
  const b64toBlob = (b64Data, contentType = 'application/octet-stream') => {
    try {
      const byteCharacters = atob(b64Data);
      const byteArrays = [];
      for (let offset = 0; offset < byteCharacters.length; offset += 1024) {
        const slice = byteCharacters.slice(offset, offset + 1024);
        const byteNumbers = new Array(slice.length);
        for (let i = 0; i < slice.length; i++) byteNumbers[i] = slice.charCodeAt(i);
        byteArrays.push(new Uint8Array(byteNumbers));
      }
      return new Blob(byteArrays, { type: contentType });
    } catch {
      return null;
    }
  };

  // Simple, local fallback mouth-cue generator (when no phonemes from API)
  const genFallbackMouthCues = (text = '', durationSec = 2.0) => {
    const letters = text
      .toLowerCase()
      .replace(/[^a-z\s]/g, '')
      .split('');
    const toViseme = (a, b) => {
      const pair = (a || '') + (b || '');
      if (pair.startsWith('th')) return 'H';
      if (/^[pbm]$/.test(a)) return 'A';
      if (/^[fv]$/.test(a)) return 'G';
      if (/^[o]$/.test(a)) return 'E';
      if (/^[uuw]$/.test(a)) return 'F';
      if (/^[a]$/.test(a)) return 'D';
      if (/^[eiiy]$/.test(a)) return 'C';
      if (/^[kgxqg]$/.test(a)) return 'B';
      if (a === ' ') return 'X';
      return 'C';
    };
    const raw = [];
    for (let i = 0; i < letters.length; i++) raw.push(toViseme(letters[i], letters[i + 1]));
    const seq = [];
    for (const v of raw) if (seq.length === 0 || seq[seq.length - 1] !== v) seq.push(v);
    const n = Math.max(1, seq.length);
    const step = durationSec / n;
    return { mouthCues: seq.map((v, i) => ({ start: i * step, end: (i + 1) * step, value: v })) };
  };

  // React to new message: set animation/facial expression/audio safely
  useEffect(() => {
    console.log(message);
    if (!message) {
      setAnimation("Idle");
      return;
    }
    const nextAnim = filteredAnimations.find((a) => a.name === message.animation)
      ? message.animation
      : (filteredAnimations[0]?.name || animation);
    setAnimation(nextAnim);
    setFacialExpression(message.facialExpression || "default");
    setLipsync(message.lipsync);
    if (message?.audio) {
      const mime = message.audioMime || 'audio/wav';
      // data can be large; prefer Blob URL for reliability
      const blob = b64toBlob(message.audio, mime);
      const url = blob ? URL.createObjectURL(blob) : `data:${mime};base64,${message.audio}`;
      const a = new Audio(url);
      // If no lipsync from API, compute a local fallback once metadata (duration) is known
      const ensureFallback = () => {
        try {
          if (!message.lipsync && isFinite(a.duration) && a.duration > 0.2) {
            setLipsync(genFallbackMouthCues(message.text || '', Math.min(a.duration, 20)));
          }
        } catch {}
      };
      a.addEventListener('loadedmetadata', ensureFallback, { once: true });
      a.addEventListener('ended', () => {
        onMessagePlayed();
        setAnimation('Idle');
        if (blob) URL.revokeObjectURL(url);
      }, { once: true });
      a.addEventListener('stalled', () => a.play().catch(()=>{}));
      a.addEventListener('waiting', () => a.play().catch(()=>{}));
      a.play().catch(()=>{});
      setAudio(a);
    } else if (message?.text && 'speechSynthesis' in window) {
      try {
        const speak = () => {
          const u = new SpeechSynthesisUtterance(message.text);
          u.rate = 1.0; u.pitch = 1.05; u.volume = 1.0;
          // Prefer a female English voice if available
          const voices = window.speechSynthesis.getVoices();
          const preferred = voices.find(v => /Zira|Jenny|Samantha|Joanna|Olivia|Aria|en\-US/i.test(v.name))
            || voices.find(v => /en\-US/i.test(v.lang))
            || voices[0];
          if (preferred) u.voice = preferred;
          u.onend = () => { onMessagePlayed(); setAnimation('Idle'); };
          window.speechSynthesis.cancel();
          window.speechSynthesis.speak(u);
        };
        if (window.speechSynthesis.getVoices().length === 0) {
          window.speechSynthesis.onvoiceschanged = () => { try { speak(); } catch {} };
        } else {
          speak();
        }
      } catch (e) {
        // Fallback: no audio; pop message to keep flow
        onMessagePlayed();
        setAnimation('Idle');
      }
    } else {
      // No audio available; pop message so queue continues
      onMessagePlayed();
      setAnimation('Idle');
    }
  }, [message, filteredAnimations, animation]);

  useEffect(() => {
    const action = actions?.[animation];
    if (!action) return;

    const isTalking = /^Talking_/.test(animation);
    action.reset();

    if (isTalking || animation === "Idle") {
      // Loop talking/idle animations softly
      action.setLoop(THREE.LoopRepeat, Infinity);
      action.clampWhenFinished = false;
      action.timeScale = 0.95; // slightly slower for more natural delivery
      action.fadeIn(0.25).play();
      return () => action.fadeOut(0.25);
    } else {
      // Emphatic animations: if audio exists, keep looping during speech, else play once and linger
      const hasAudio = Boolean(audio);
      if (hasAudio) {
        action.setLoop(THREE.LoopRepeat, Infinity);
        action.clampWhenFinished = false;
        action.timeScale = 0.85; // slow down for more expressiveness
        action.fadeIn(0.25).play();
        const endHandler = () => setAnimation("Idle");
        // On cleanup, detach; Idle will be set by audio.onended in message effect as well
        return () => {
          action.fadeOut(0.25);
        };
      } else {
        action.setLoop(THREE.LoopOnce, 1);
        action.clampWhenFinished = true;
        action.timeScale = 0.9;
        const toIdle = () => setAnimation("Idle");
        mixer.addEventListener("finished", toIdle);
        // Linger a bit after finish so it doesn't feel abrupt
        const duration = (action.getClip()?.duration || 2.0) * (1 / (action.timeScale || 1));
        const timer = setTimeout(() => setAnimation("Idle"), Math.max(1200, duration * 1000 + 500));
        action.fadeIn(0.25).play();
        return () => {
          clearTimeout(timer);
          mixer.removeEventListener("finished", toIdle);
          action.fadeOut(0.25);
        };
      }
    }
  }, [animation, actions, mixer, audio]);

  const lerpMorphTarget = (target, value, speed = 0.1) => {
    scene.traverse((child) => {
      if (child.isSkinnedMesh && child.morphTargetDictionary) {
        const index = child.morphTargetDictionary[target];
        if (
          index === undefined ||
          child.morphTargetInfluences[index] === undefined
        ) {
          return;
        }
        child.morphTargetInfluences[index] = THREE.MathUtils.lerp(
          child.morphTargetInfluences[index],
          value,
          speed
        );

        if (!setupMode) {
          try {
            set({
              [target]: value,
            });
          } catch (e) {}
        }
      }
    });
  };

  const [blink, setBlink] = useState(false);
  const [winkLeft, setWinkLeft] = useState(false);
  const [winkRight, setWinkRight] = useState(false);
  const [facialExpression, setFacialExpression] = useState("");

  useFrame(() => {
    if (group.current) {
      group.current.position.set(0, 0, 0);
      group.current.scale.set(1, 1, 1);
    }
    !setupMode && nodes?.EyeLeft &&
      Object.keys(nodes.EyeLeft.morphTargetDictionary).forEach((key) => {
        const mapping = facialExpressions[facialExpression];
        if (key === "eyeBlinkLeft" || key === "eyeBlinkRight") {
          return; // eyes wink/blink are handled separately
        }
        if (mapping && mapping[key]) {
          lerpMorphTarget(key, mapping[key], 0.1);
        } else {
          lerpMorphTarget(key, 0, 0.1);
        }
      });

    lerpMorphTarget("eyeBlinkLeft", blink || winkLeft ? 1 : 0, 0.5);
    lerpMorphTarget("eyeBlinkRight", blink || winkRight ? 1 : 0, 0.5);

    // LIPSYNC
    if (setupMode) {
      return;
    }

    const appliedMorphTargets = [];
    if (message && lipsync && audio) {
      const currentAudioTime = audio.currentTime;
      for (let i = 0; i < lipsync.mouthCues.length; i++) {
        const mouthCue = lipsync.mouthCues[i];
        if (
          currentAudioTime >= mouthCue.start &&
          currentAudioTime <= mouthCue.end
        ) {
          appliedMorphTargets.push(corresponding[mouthCue.value]);
          lerpMorphTarget(corresponding[mouthCue.value], 1, 0.2);
          break;
        }
      }
    }

    Object.values(corresponding).forEach((value) => {
      if (appliedMorphTargets.includes(value)) {
        return;
      }
      lerpMorphTarget(value, 0, 0.1);
    });
  });

  useControls("FacialExpressions", {
    chat: button(() => chat()),
    winkLeft: button(() => {
      setWinkLeft(true);
      setTimeout(() => setWinkLeft(false), 300);
    }),
    winkRight: button(() => {
      setWinkRight(true);
      setTimeout(() => setWinkRight(false), 300);
    }),
    animation: {
      value: animation,
      options: filteredAnimations.map((a) => a.name),
      onChange: (value) => setAnimation(value),
    },
    facialExpression: {
      options: Object.keys(facialExpressions),
      onChange: (value) => setFacialExpression(value),
    },
    enableSetupMode: button(() => {
      setupMode = true;
    }),
    disableSetupMode: button(() => {
      setupMode = false;
    }),
    logMorphTargetValues: button(() => {
      const emotionValues = {};
      Object.keys(nodes.EyeLeft.morphTargetDictionary).forEach((key) => {
        if (key === "eyeBlinkLeft" || key === "eyeBlinkRight") {
          return; // eyes wink/blink are handled separately
        }
        const value =
          nodes.EyeLeft.morphTargetInfluences[
            nodes.EyeLeft.morphTargetDictionary[key]
          ];
        if (value > 0.01) {
          emotionValues[key] = value;
        }
      });
      console.log(JSON.stringify(emotionValues, null, 2));
    }),
  });

  const [, set] = useControls("MorphTarget", () =>
    Object.assign(
      {},
      ...Object.keys(nodes.EyeLeft.morphTargetDictionary).map((key) => {
        return {
          [key]: {
            label: key,
            value: 0,
            min: nodes.EyeLeft.morphTargetInfluences[
              nodes.EyeLeft.morphTargetDictionary[key]
            ],
            max: 1,
            onChange: (val) => {
              if (setupMode) {
                lerpMorphTarget(key, val, 1);
              }
            },
          },
        };
      })
    )
  );

  useEffect(() => {
    let blinkTimeout;
    const nextBlink = () => {
      blinkTimeout = setTimeout(() => {
        setBlink(true);
        setTimeout(() => {
          setBlink(false);
          nextBlink();
        }, 200);
      }, THREE.MathUtils.randInt(1000, 5000));
    };
    nextBlink();
    return () => clearTimeout(blinkTimeout);
  }, []);

  return (
    <group {...props} dispose={null} ref={group}>
      <primitive object={nodes.Hips} />
      <skinnedMesh
        name="Wolf3D_Body"
        geometry={nodes.Wolf3D_Body.geometry}
        material={materials.Wolf3D_Body}
        skeleton={nodes.Wolf3D_Body.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Outfit_Bottom"
        geometry={nodes.Wolf3D_Outfit_Bottom.geometry}
        material={materials.Wolf3D_Outfit_Bottom}
        skeleton={nodes.Wolf3D_Outfit_Bottom.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Outfit_Footwear"
        geometry={nodes.Wolf3D_Outfit_Footwear.geometry}
        material={materials.Wolf3D_Outfit_Footwear}
        skeleton={nodes.Wolf3D_Outfit_Footwear.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Outfit_Top"
        geometry={nodes.Wolf3D_Outfit_Top.geometry}
        material={materials.Wolf3D_Outfit_Top}
        skeleton={nodes.Wolf3D_Outfit_Top.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Hair"
        geometry={nodes.Wolf3D_Hair.geometry}
        material={materials.Wolf3D_Hair}
        skeleton={nodes.Wolf3D_Hair.skeleton}
      />
      <skinnedMesh
        name="EyeLeft"
        geometry={nodes.EyeLeft.geometry}
        material={materials.Wolf3D_Eye}
        skeleton={nodes.EyeLeft.skeleton}
        morphTargetDictionary={nodes.EyeLeft.morphTargetDictionary}
        morphTargetInfluences={nodes.EyeLeft.morphTargetInfluences}
      />
      <skinnedMesh
        name="EyeRight"
        geometry={nodes.EyeRight.geometry}
        material={materials.Wolf3D_Eye}
        skeleton={nodes.EyeRight.skeleton}
        morphTargetDictionary={nodes.EyeRight.morphTargetDictionary}
        morphTargetInfluences={nodes.EyeRight.morphTargetInfluences}
      />
      <skinnedMesh
        name="Wolf3D_Head"
        geometry={nodes.Wolf3D_Head.geometry}
        material={materials.Wolf3D_Skin}
        skeleton={nodes.Wolf3D_Head.skeleton}
        morphTargetDictionary={nodes.Wolf3D_Head.morphTargetDictionary}
        morphTargetInfluences={nodes.Wolf3D_Head.morphTargetInfluences}
      />
      <skinnedMesh
        name="Wolf3D_Teeth"
        geometry={nodes.Wolf3D_Teeth.geometry}
        material={materials.Wolf3D_Teeth}
        skeleton={nodes.Wolf3D_Teeth.skeleton}
        morphTargetDictionary={nodes.Wolf3D_Teeth.morphTargetDictionary}
        morphTargetInfluences={nodes.Wolf3D_Teeth.morphTargetInfluences}
      />
    </group>
  );
}

useGLTF.preload("/models/64f1a714fe61576b46f27ca2.glb");
useGLTF.preload("/models/animations.glb");
